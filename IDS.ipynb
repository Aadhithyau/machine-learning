{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Download NSL-KDD (real IDS dataset)\n",
        "# -----------------------------\n",
        "TRAIN_URL = \"https://raw.githubusercontent.com/Jehuty4949/NSL_KDD/master/KDDTrain%2B.txt\"\n",
        "TEST_URL  = \"https://raw.githubusercontent.com/Jehuty4949/NSL_KDD/master/KDDTest%2B.txt\"\n",
        "\n",
        "train_txt = requests.get(TRAIN_URL, timeout=60).text\n",
        "test_txt  = requests.get(TEST_URL, timeout=60).text\n",
        "\n",
        "# NSL-KDD columns: 41 features + label + difficulty\n",
        "cols = [\n",
        "    \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\n",
        "    \"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\n",
        "    \"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
        "    \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\n",
        "    \"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\n",
        "    \"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\n",
        "    \"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\n",
        "    \"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
        "    \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\n",
        "    \"label\",\"difficulty\"\n",
        "]\n",
        "\n",
        "train_df = pd.read_csv(StringIO(train_txt), header=None, names=cols)\n",
        "test_df  = pd.read_csv(StringIO(test_txt), header=None, names=cols)\n",
        "\n",
        "# Combine train+test, then do our own split (cleaner for assignment)\n",
        "df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Binary target: Normal vs Attack\n",
        "# -----------------------------\n",
        "# normal -> 0, everything else -> 1\n",
        "y = (df[\"label\"].astype(str).str.strip() != \"normal\").astype(int)\n",
        "\n",
        "# Drop label + difficulty from features\n",
        "X = df.drop(columns=[\"label\", \"difficulty\"])\n",
        "\n",
        "print(\"Total rows:\", len(df))\n",
        "print(\"Normal:\", (y == 0).sum(), \"Attack:\", (y == 1).sum())\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Identify numeric vs categorical columns\n",
        "# -----------------------------\n",
        "categorical_cols = [\"protocol_type\", \"service\", \"flag\"]\n",
        "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Preprocessing pipelines\n",
        "# -----------------------------\n",
        "num_scaled = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "num_noscale = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
        "])\n",
        "\n",
        "cat_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "# For NB + ANN (scaling helps)\n",
        "preprocess_scaled = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_scaled, numeric_cols),\n",
        "        (\"cat\", cat_pipe, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# For Decision Tree (no scaling needed)\n",
        "preprocess_tree = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_noscale, numeric_cols),\n",
        "        (\"cat\", cat_pipe, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Train-test split\n",
        "# -----------------------------\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 6) Model A: Bayesian (Gaussian Naive Bayes)\n",
        "# -----------------------------\n",
        "nb_model = Pipeline(steps=[\n",
        "    (\"prep\", preprocess_scaled),\n",
        "    (\"clf\", GaussianNB())\n",
        "])\n",
        "\n",
        "nb_model.fit(X_tr, y_tr)\n",
        "nb_pred = nb_model.predict(X_te)\n",
        "\n",
        "print(\"\\n=== Gaussian Naive Bayes (IDS) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_te, nb_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, nb_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(\n",
        "    y_te, nb_pred, target_names=[\"Normal\", \"Attack\"], zero_division=0\n",
        "))\n",
        "\n",
        "# -----------------------------\n",
        "# 7) Model B: Decision Tree (Entropy)\n",
        "# -----------------------------\n",
        "dt_model = Pipeline(steps=[\n",
        "    (\"prep\", preprocess_tree),\n",
        "    (\"clf\", DecisionTreeClassifier(\n",
        "        criterion=\"entropy\",\n",
        "        max_depth=15,\n",
        "        min_samples_leaf=10,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "dt_model.fit(X_tr, y_tr)\n",
        "dt_pred = dt_model.predict(X_te)\n",
        "\n",
        "print(\"\\n=== Decision Tree (Entropy) (IDS) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_te, dt_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, dt_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(\n",
        "    y_te, dt_pred, target_names=[\"Normal\", \"Attack\"], zero_division=0\n",
        "))\n",
        "\n",
        "# -----------------------------\n",
        "# 8) Model C: ANN (MLP)\n",
        "# -----------------------------\n",
        "ann_model = Pipeline(steps=[\n",
        "    (\"prep\", preprocess_scaled),\n",
        "    (\"clf\", MLPClassifier(\n",
        "        hidden_layer_sizes=(64, 32),\n",
        "        activation=\"relu\",\n",
        "        max_iter=30,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "ann_model.fit(X_tr, y_tr)\n",
        "ann_pred = ann_model.predict(X_te)\n",
        "\n",
        "print(\"\\n=== ANN (MLP) (IDS) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_te, ann_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, ann_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(\n",
        "    y_te, ann_pred, target_names=[\"Normal\", \"Attack\"], zero_division=0\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndj5wtfPszQw",
        "outputId": "38a1cf0a-000d-4b25-d19c-0c0e46bd67c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows: 148517\n",
            "Normal: 77054 Attack: 71463\n",
            "\n",
            "=== Gaussian Naive Bayes (IDS) ===\n",
            "Accuracy: 0.8149474818206303\n",
            "Confusion Matrix:\n",
            " [[19181    83]\n",
            " [ 6788 11078]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.74      1.00      0.85     19264\n",
            "      Attack       0.99      0.62      0.76     17866\n",
            "\n",
            "    accuracy                           0.81     37130\n",
            "   macro avg       0.87      0.81      0.81     37130\n",
            "weighted avg       0.86      0.81      0.81     37130\n",
            "\n",
            "\n",
            "=== Decision Tree (Entropy) (IDS) ===\n",
            "Accuracy: 0.9927821168866146\n",
            "Confusion Matrix:\n",
            " [[19155   109]\n",
            " [  159 17707]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      0.99      0.99     19264\n",
            "      Attack       0.99      0.99      0.99     17866\n",
            "\n",
            "    accuracy                           0.99     37130\n",
            "   macro avg       0.99      0.99      0.99     37130\n",
            "weighted avg       0.99      0.99      0.99     37130\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ANN (MLP) (IDS) ===\n",
            "Accuracy: 0.9914085645030972\n",
            "Confusion Matrix:\n",
            " [[19082   182]\n",
            " [  137 17729]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      0.99      0.99     19264\n",
            "      Attack       0.99      0.99      0.99     17866\n",
            "\n",
            "    accuracy                           0.99     37130\n",
            "   macro avg       0.99      0.99      0.99     37130\n",
            "weighted avg       0.99      0.99      0.99     37130\n",
            "\n"
          ]
        }
      ]
    }
  ]
}