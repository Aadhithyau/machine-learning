{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc1puLtiy0Rw",
        "outputId": "0ab35894-abd2-4350-ef33-5438870d61cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: OpenML lung-cancer\n",
            "\n",
            "Dataset shape: (32, 56)\n",
            "Numeric cols: 56 Categorical cols: 0\n",
            "Classes: ['1' '2' '3']\n",
            "\n",
            "==============================\n",
            "MODEL: Gaussian Naive Bayes\n",
            "==============================\n",
            "Accuracy: 0.625\n",
            "Confusion Matrix:\n",
            " [[0 1 1]\n",
            " [1 2 0]\n",
            " [0 0 3]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.67      0.67      0.67         3\n",
            "           3       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.62         8\n",
            "   macro avg       0.47      0.56      0.51         8\n",
            "weighted avg       0.53      0.62      0.57         8\n",
            "\n",
            "\n",
            "==============================\n",
            "MODEL: Decision Tree (Entropy)\n",
            "==============================\n",
            "Accuracy: 0.75\n",
            "Confusion Matrix:\n",
            " [[1 0 1]\n",
            " [1 2 0]\n",
            " [0 0 3]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.50      0.50         2\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.75      0.72      0.72         8\n",
            "weighted avg       0.78      0.75      0.75         8\n",
            "\n",
            "\n",
            "==============================\n",
            "MODEL: ANN (MLP)\n",
            "==============================\n",
            "Accuracy: 0.375\n",
            "Confusion Matrix:\n",
            " [[1 1 0]\n",
            " [0 0 3]\n",
            " [0 1 2]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.40      0.67      0.50         3\n",
            "\n",
            "    accuracy                           0.38         8\n",
            "   macro avg       0.47      0.39      0.39         8\n",
            "weighted avg       0.40      0.38      0.35         8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Load Lung Cancer dataset (TRY OpenML first, else fallback)\n",
        "# ------------------------------------------------------------\n",
        "def load_lung_cancer():\n",
        "    # ---- Option A: OpenML (preferred) ----\n",
        "    try:\n",
        "        from sklearn.datasets import fetch_openml\n",
        "        X, y = fetch_openml(name=\"lung-cancer\", as_frame=True, return_X_y=True)\n",
        "        df = X.copy()\n",
        "        df[\"target\"] = y\n",
        "        print(\"Loaded: OpenML lung-cancer\")\n",
        "        return df, \"target\"\n",
        "    except Exception as e:\n",
        "        print(\"OpenML load failed, trying UCI fallback...\")\n",
        "\n",
        "    # ---- Option B: UCI fallback (small classic dataset; contains '?' missing values) ----\n",
        "    # UCI Lung Cancer dataset is often mirrored; this is a common raw mirror:\n",
        "    # If this mirror is blocked in your environment, the code will still tell you what failed.\n",
        "    import requests\n",
        "    from io import StringIO\n",
        "\n",
        "    uci_url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/lung-cancer.csv\"\n",
        "    try:\n",
        "        csv_text = requests.get(uci_url, timeout=60).text\n",
        "        # This dataset usually has class in the first column followed by attributes\n",
        "        df = pd.read_csv(StringIO(csv_text), header=None)\n",
        "        df = df.replace(\"?\", np.nan)\n",
        "\n",
        "        # first column is target\n",
        "        df = df.rename(columns={0: \"target\"})\n",
        "        print(\"Loaded: UCI lung-cancer (GitHub mirror)\")\n",
        "        return df, \"target\"\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\n",
        "            \"Could not load Lung Cancer dataset from OpenML or the UCI mirror. \"\n",
        "            \"If your network blocks downloads, upload the dataset CSV and I’ll adapt the code instantly.\"\n",
        "        )\n",
        "\n",
        "df, target_col = load_lung_cancer()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Separate X and y\n",
        "# ------------------------------------------------------------\n",
        "y = df[target_col]\n",
        "X = df.drop(columns=[target_col])\n",
        "\n",
        "# If target is non-numeric labels, encode to integers\n",
        "if y.dtype == \"object\" or str(y.dtype).startswith(\"string\"):\n",
        "    y = y.astype(str).str.strip()\n",
        "    y = pd.Series(LabelEncoder().fit_transform(y), name=\"target\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Identify numeric/categorical columns (robust)\n",
        "# ------------------------------------------------------------\n",
        "# Convert numeric-looking columns safely; keep others categorical\n",
        "X_numeric = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "numeric_cols = X_numeric.columns[X_numeric.notna().any()].tolist()\n",
        "\n",
        "# columns that are not reliably numeric are treated as categorical\n",
        "categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
        "\n",
        "# Build a clean working X where numeric cols are numeric\n",
        "X_clean = X.copy()\n",
        "for c in numeric_cols:\n",
        "    X_clean[c] = pd.to_numeric(X_clean[c], errors=\"coerce\")\n",
        "\n",
        "print(\"\\nDataset shape:\", X_clean.shape)\n",
        "print(\"Numeric cols:\", len(numeric_cols), \"Categorical cols:\", len(categorical_cols))\n",
        "print(\"Classes:\", np.unique(y))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Train-test split\n",
        "# ------------------------------------------------------------\n",
        "# Stratify only if every class has at least 2 samples in this split\n",
        "# (This dataset is small, so stratify may fail in rare cases; handle safely.)\n",
        "try:\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X_clean, y, test_size=0.25, random_state=42, stratify=y\n",
        "    )\n",
        "except Exception:\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X_clean, y, test_size=0.25, random_state=42\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Preprocessing pipelines\n",
        "# ------------------------------------------------------------\n",
        "# For Naive Bayes + ANN (scaling helps)\n",
        "num_scaled = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# For Decision Tree (no scaling needed)\n",
        "num_noscale = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
        "])\n",
        "\n",
        "cat_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocess_scaled = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_scaled, numeric_cols),\n",
        "        (\"cat\", cat_pipe, categorical_cols)\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "preprocess_tree = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_noscale, numeric_cols),\n",
        "        (\"cat\", cat_pipe, categorical_cols)\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Model A — Bayesian Classification (GaussianNB)\n",
        "# ------------------------------------------------------------\n",
        "nb_model = Pipeline(steps=[\n",
        "    (\"prep\", preprocess_scaled),\n",
        "    (\"clf\", GaussianNB())\n",
        "])\n",
        "\n",
        "nb_model.fit(X_tr, y_tr)\n",
        "nb_pred = nb_model.predict(X_te)\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"MODEL: Gaussian Naive Bayes\")\n",
        "print(\"==============================\")\n",
        "print(\"Accuracy:\", accuracy_score(y_te, nb_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, nb_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_te, nb_pred, zero_division=0))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Model B — Decision Tree (Entropy)\n",
        "# ------------------------------------------------------------\n",
        "dt_model = Pipeline(steps=[\n",
        "    (\"prep\", preprocess_tree),\n",
        "    (\"clf\", DecisionTreeClassifier(\n",
        "        criterion=\"entropy\",\n",
        "        max_depth=10,         # control overfitting\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "dt_model.fit(X_tr, y_tr)\n",
        "dt_pred = dt_model.predict(X_te)\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"MODEL: Decision Tree (Entropy)\")\n",
        "print(\"==============================\")\n",
        "print(\"Accuracy:\", accuracy_score(y_te, dt_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, dt_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_te, dt_pred, zero_division=0))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 8) Model C — ANN (MLPClassifier)\n",
        "# ------------------------------------------------------------\n",
        "ann_model = Pipeline(steps=[\n",
        "    (\"prep\", preprocess_scaled),\n",
        "    (\"clf\", MLPClassifier(\n",
        "        hidden_layer_sizes=(64, 32),\n",
        "        activation=\"relu\",\n",
        "        max_iter=800,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "ann_model.fit(X_tr, y_tr)\n",
        "ann_pred = ann_model.predict(X_te)\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"MODEL: ANN (MLP)\")\n",
        "print(\"==============================\")\n",
        "print(\"Accuracy:\", accuracy_score(y_te, ann_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, ann_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_te, ann_pred, zero_division=0))\n"
      ]
    }
  ]
}