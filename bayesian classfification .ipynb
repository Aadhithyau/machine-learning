{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6dxTvGuQSpa7U/410VZSi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gk900LgODYMN","executionInfo":{"status":"ok","timestamp":1755870786870,"user_tz":-330,"elapsed":32,"user":{"displayName":"Aadhithya .U","userId":"10970561894782391279"}},"outputId":"094c361f-b5a0-4e47-d42b-40b23b4eb70f"},"outputs":[{"output_type":"stream","name":"stdout","text":["From-scratch Naive Bayes (categorical):\n","Posterior probabilities: {'no': np.float64(0.23217141029740956), 'yes': np.float64(0.7678285897025904)}\n","Prediction: yes\n"]}],"source":["import numpy as np\n","from collections import defaultdict, Counter\n","\n","# --------------------------\n","# Dataset (14 rows, categorical)\n","# --------------------------\n","data = [\n","    # age,     income,  student, credit,     buys_computer\n","    (\"<=30\",   \"high\",  \"no\",    \"fair\",     \"no\"),\n","    (\"<=30\",   \"high\",  \"no\",    \"excellent\",\"no\"),\n","    (\"31..40\", \"high\",  \"no\",    \"fair\",     \"yes\"),\n","    (\">40\",    \"medium\",\"no\",    \"fair\",     \"yes\"),\n","    (\">40\",    \"low\",   \"yes\",   \"fair\",     \"yes\"),\n","    (\">40\",    \"low\",   \"yes\",   \"excellent\",\"no\"),\n","    (\"31..40\", \"low\",   \"yes\",   \"excellent\",\"yes\"),\n","    (\"<=30\",   \"medium\",\"no\",    \"fair\",     \"no\"),\n","    (\"<=30\",   \"low\",   \"yes\",   \"fair\",     \"yes\"),\n","    (\">40\",    \"medium\",\"yes\",   \"fair\",     \"yes\"),\n","    (\"<=30\",   \"medium\",\"yes\",   \"excellent\",\"yes\"),\n","    (\"31..40\", \"medium\",\"no\",    \"excellent\",\"yes\"),\n","    (\"31..40\", \"high\",  \"yes\",   \"fair\",     \"yes\"),\n","    (\">40\",    \"medium\",\"no\",    \"excellent\",\"no\"),\n","]\n","\n","X = [tuple(row[:-1]) for row in data]     # features\n","y = [row[-1] for row in data]             # labels\n","features = [\"age\", \"income\", \"student\", \"credit\"]\n","\n","# Query sample:\n","x_query = (\"<=30\", \"medium\", \"yes\", \"fair\")\n","\n","# --------------------------\n","# Build frequency tables with Laplace smoothing\n","# --------------------------\n","classes = sorted(set(y))\n","n = len(y)\n","\n","# prior counts\n","class_counts = Counter(y)\n","\n","# For each feature position, collect the set of possible categorical values (for smoothing)\n","value_spaces = [sorted(set(col[i] for col in X)) for i in range(len(features))]\n","\n","# likelihood counts: counts[(class, feature_idx, feature_value)]\n","counts = defaultdict(int)\n","for xi, yi in zip(X, y):\n","    for j, v in enumerate(xi):\n","        counts[(yi, j, v)] += 1\n","\n","def posterior_logprob(x):\n","    \"\"\"Return log posterior for each class with Laplace smoothing (alpha=1).\"\"\"\n","    alpha = 1.0\n","    logps = {}\n","    for c in classes:\n","        # log prior\n","        logp = np.log((class_counts[c]) / n)\n","        # multiply likelihoods (add logs)\n","        for j, v in enumerate(x):\n","            Vj = len(value_spaces[j])                      # number of categories for feature j\n","            num = counts[(c, j, v)] + alpha               # smoothed count\n","            den = class_counts[c] + alpha * Vj            # smoothed total\n","            logp += np.log(num / den)\n","        logps[c] = logp\n","    return logps\n","\n","# --------------------------\n","# Predict & show posterior\n","# --------------------------\n","logps = posterior_logprob(x_query)\n","# normalize to probabilities\n","maxlog = max(logps.values())\n","probs = {c: np.exp(lp - maxlog) for c, lp in logps.items()}\n","Z = sum(probs.values())\n","probs = {c: p/Z for c, p in probs.items()}\n","pred = max(probs, key=probs.get)\n","\n","print(\"From-scratch Naive Bayes (categorical):\")\n","print(\"Posterior probabilities:\", probs)\n","print(\"Prediction:\", pred)\n"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.naive_bayes import CategoricalNB\n","\n","# Same dataset\n","X_cat = np.array([row[:-1] for row in data], dtype=object)\n","y_cat = np.array([row[-1]  for row in data], dtype=object)\n","\n","# Encode categorical features as integers for CategoricalNB\n","enc = OrdinalEncoder()\n","X_enc = enc.fit_transform(X_cat)\n","\n","# Encode labels to {0,1} implicitly handled by CategoricalNB; we can keep strings in y\n","clf = CategoricalNB(alpha=1.0)   # Laplace smoothing\n","clf.fit(X_enc, y_cat)\n","\n","# Transform the query sample and predict\n","xq_enc = enc.transform(np.array([x_query], dtype=object))\n","pred_skl = clf.predict(xq_enc)[0]\n","proba_skl = dict(zip(clf.classes_, clf.predict_proba(xq_enc)[0]))\n","\n","print(\"\\nscikit-learn CategoricalNB:\")\n","print(\"Posterior probabilities:\", proba_skl)\n","print(\"Prediction:\", pred_skl)\n"],"metadata":{"id":"BXtwoaKBDpHY","executionInfo":{"status":"ok","timestamp":1755870834284,"user_tz":-330,"elapsed":3654,"user":{"displayName":"Aadhithya .U","userId":"10970561894782391279"}},"outputId":"27f8db67-5c34-498d-8b48-5c4e14e25ceb","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","scikit-learn CategoricalNB:\n","Posterior probabilities: {np.str_('no'): np.float64(0.2321714102974098), np.str_('yes'): np.float64(0.7678285897025902)}\n","Prediction: yes\n"]}]}]}