{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMl64iFdxcOeU8eTA4+qIdx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","\n","def sigmoid(x):\n","    return 1.0 / (1.0 + np.exp(-x))\n","\n","def d_sigmoid(a):\n","    return a * (1.0 - a)\n","\n","class DenseLayer:\n","    \"\"\"A fully-connected layer with sigmoid activation.\"\"\"\n","    def __init__(self, n_in, n_out, lr=0.9, W=None, b=None, name=\"\"):\n","        self.n_in = n_in\n","        self.n_out = n_out\n","        self.lr = lr\n","        self.name = name\n","\n","        # Parameters (attributes)\n","        self.W = np.array(W, dtype=float) if W is not None else np.random.randn(n_in, n_out) * 0.1\n","        self.b = np.array(b, dtype=float) if b is not None else np.zeros(n_out)\n","\n","        # Caches for backprop\n","        self.X = None          # input to this layer\n","        self.Z = None          # net input\n","        self.A = None          # activation (output)\n","\n","    # ---- forward & backward ----\n","    def forward(self, X):\n","        self.X = X                       # (batch, n_in)\n","        self.Z = X @ self.W + self.b     # (batch, n_out)\n","        self.A = sigmoid(self.Z)         # (batch, n_out)\n","        return self.A\n","\n","    def backward_output(self, T):\n","        \"\"\"Backprop for output layer: Err = O*(1-O)*(T-O). Updates params.\"\"\"\n","        O = self.A\n","        delta = d_sigmoid(O) * (T - O)                # (batch, n_out)\n","        dW = self.X.T @ delta                         # (n_in, n_out)\n","        db = delta.sum(axis=0)                        # (n_out,)\n","        self.W += self.lr * dW\n","        self.b += self.lr * db\n","        return delta\n","\n","    def backward_hidden(self, next_W, next_delta):\n","        \"\"\"Backprop for hidden layer: Err = O*(1-O) * (next_delta @ next_W^T).\"\"\"\n","        O = self.A\n","        backflow = next_delta @ next_W.T              # (batch, n_out_this)\n","        delta = d_sigmoid(O) * backflow\n","        dW = self.X.T @ delta\n","        db = delta.sum(axis=0)\n","        self.W += self.lr * dW\n","        self.b += self.lr * db\n","        return delta\n","\n","class NeuralNetwork321:\n","    \"\"\"3-2-1 network: input(3) -> hidden(2) -> output(1) with sigmoid and backprop.\"\"\"\n","    def __init__(self, lr=0.9, init_from_table=True):\n","        self.lr = lr\n","\n","        if init_from_table:\n","            # From your table:\n","            W_ih = [[ 0.2, -0.3],\n","                    [ 0.4,  0.1],\n","                    [-0.5,  0.2]]\n","            b_h  = [-0.4, 0.2]\n","            W_ho = [[-0.3],\n","                    [-0.2]]\n","            b_o  = [0.1]\n","        else:\n","            W_ih = b_h = W_ho = b_o = None\n","\n","        self.hidden = DenseLayer(3, 2, lr=lr, W=W_ih, b=b_h, name=\"hidden\")\n","        self.out    = DenseLayer(2, 1, lr=lr, W=W_ho, b=b_o, name=\"output\")\n","\n","    # ---- API ----\n","    def forward(self, X):\n","        H = self.hidden.forward(X)\n","        O = self.out.forward(H)\n","        return O\n","\n","    def backward_one_step(self, T):\n","        delta_out = self.out.backward_output(T)\n","        _ = self.hidden.backward_hidden(self.out.W, delta_out)\n","        return delta_out, _\n","\n","    def train_one_step_verbose(self, X, T):\n","        # Forward\n","        O_hidden = self.hidden.forward(X)\n","        O_out = self.out.forward(O_hidden)\n","\n","        # Print Table 6.4 (net inputs & outputs)\n","        I4, I5 = self.hidden.Z.ravel()\n","        I6 = self.out.Z.ravel()[0]\n","        O4, O5 = O_hidden.ravel()\n","        O6 = O_out.ravel()[0]\n","        print(f\"Net inputs (I4, I5, I6): {I4:.3f}, {I5:.3f}, {I6:.3f}\")\n","        print(f\"Outputs    (O4, O5, O6): {O4:.3f}, {O5:.3f}, {O6:.3f}\")\n","\n","        # Backward\n","        delta_out = self.out.backward_output(T)                         # Err6\n","        delta_hid = self.hidden.backward_hidden(self.out.W, delta_out)  # Err4, Err5\n","\n","        # Print Table 6.5 (errors)\n","        Err6 = float(delta_out.ravel()[0])\n","        Err4, Err5 = delta_hid.ravel()[0], delta_hid.ravel()[1]\n","        print(f\"Err6: {Err6:.4f}\")\n","        print(f\"Err5: {Err5:.4f}, Err4: {Err4:.4f}\")\n","\n","        # Print Table 6.6 (updated params)\n","        W_ih, b_h = self.hidden.W, self.hidden.b\n","        W_ho, b_o = self.out.W, self.out.b\n","        print(\"\\nUpdated weights/biases (η=0.9):\")\n","        print(f\"w46: {W_ho[0,0]:.3f}, w56: {W_ho[1,0]:.3f}\")\n","        print(\"w14..w35 rows (x1,x2,x3 -> [4,5]):\")\n","        print(np.round(W_ih, 3))\n","        print(f\"θ6: {b_o[0]:.3f}\")\n","        print(f\"θ5: {b_h[1]:.3f}, θ4: {b_h[0]:.3f}\")\n","\n","# ------------------- demo -------------------\n","if __name__ == \"__main__\":\n","    # Input and target from your example\n","    X = np.array([[1.0, 0.0, 1.0]])   # (x1, x2, x3)\n","    T = np.array([[1.0]])             # target\n","\n","    nn = NeuralNetwork321(lr=0.9, init_from_table=True)\n","    nn.train_one_step_verbose(X, T)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yRQYC_w5UFyV","executionInfo":{"status":"ok","timestamp":1754745217012,"user_tz":-330,"elapsed":105,"user":{"displayName":"Aadhithya .U","userId":"10970561894782391279"}},"outputId":"bdae30c8-c101-440d-bb14-cde4c8db318d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Net inputs (I4, I5, I6): -0.700, 0.100, -0.105\n","Outputs    (O4, O5, O6): 0.332, 0.525, 0.474\n","Err6: 0.1312\n","Err5: -0.0045, Err4: -0.0076\n","\n","Updated weights/biases (η=0.9):\n","w46: -0.261, w56: -0.138\n","w14..w35 rows (x1,x2,x3 -> [4,5]):\n","[[ 0.193 -0.304]\n"," [ 0.4    0.1  ]\n"," [-0.507  0.196]]\n","θ6: 0.218\n","θ5: 0.196, θ4: -0.407\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","def sigmoid(x):\n","    return 1.0 / (1.0 + np.exp(-x))\n","\n","def d_sigmoid(a):\n","    return a * (1.0 - a)\n","\n","class DenseLayer:\n","    def __init__(self, n_in, n_out, lr=0.9, W=None, b=None, name=\"\"):\n","        self.n_in = n_in\n","        self.n_out = n_out\n","        self.lr = lr\n","        self.name = name\n","        self.W = np.array(W, dtype=float) if W is not None else np.random.randn(n_in, n_out) * 0.1\n","        self.b = np.array(b, dtype=float) if b is not None else np.zeros(n_out)\n","        self.X = None\n","        self.Z = None\n","        self.A = None\n","\n","    def forward(self, X):\n","        self.X = X\n","        self.Z = X @ self.W + self.b\n","        self.A = sigmoid(self.Z)\n","        return self.A\n","\n","    def backward_output(self, T):\n","        O = self.A\n","        delta = d_sigmoid(O) * (T - O)\n","        dW = self.X.T @ delta\n","        db = delta.sum(axis=0)\n","        self.W += self.lr * dW\n","        self.b += self.lr * db\n","        return delta\n","\n","    def backward_hidden(self, next_W, next_delta):\n","        O = self.A\n","        backflow = next_delta @ next_W.T\n","        delta = d_sigmoid(O) * backflow\n","        dW = self.X.T @ delta\n","        db = delta.sum(axis=0)\n","        self.W += self.lr * dW\n","        self.b += self.lr * db\n","        return delta\n","\n","class NeuralNetwork432:\n","    \"\"\"4 -> 3 -> 2\"\"\"\n","    def __init__(self, lr=0.9, init_params=None):\n","        self.lr = lr\n","        # init_params: [(W_in_hidden, b_hidden), (W_hidden_out, b_out)]\n","        if init_params is not None:\n","            (W1, b1), (W2, b2) = init_params\n","        else:\n","            W1 = b1 = W2 = b2 = None\n","        self.hidden = DenseLayer(4, 3, lr=lr, W=W1, b=b1, name=\"hidden\")\n","        self.out    = DenseLayer(3, 2, lr=lr, W=W2, b=b2, name=\"output\")\n","\n","    def forward(self, X):\n","        H = self.hidden.forward(X)\n","        O = self.out.forward(H)\n","        return O\n","\n","    def backward_one_step(self, T):\n","        delta_out = self.out.backward_output(T)\n","        _ = self.hidden.backward_hidden(self.out.W, delta_out)\n","        return delta_out, _\n","\n","    def train_one_step_verbose(self, X, T):\n","        # forward\n","        H = self.hidden.forward(X)\n","        O = self.out.forward(H)\n","        print(\"[Forward] hidden Z:\", np.round(self.hidden.Z, 6))\n","        print(\"[Forward] hidden A:\", np.round(self.hidden.A, 6))\n","        print(\"[Forward] output Z:\", np.round(self.out.Z, 6))\n","        print(\"[Forward] output A:\", np.round(self.out.A, 6))\n","        # backward (output)\n","        O_last = self.out.A\n","        delta_out = d_sigmoid(O_last) * (T - O_last)\n","        print(\"[Backward] output delta:\", np.round(delta_out, 6))\n","        dW = self.out.X.T @ delta_out\n","        db = delta_out.sum(axis=0)\n","        self.out.W += self.lr * dW\n","        self.out.b += self.lr * db\n","        print(\"[Update] output W:\\n\", np.round(self.out.W, 6))\n","        print(\"[Update] output b:\", np.round(self.out.b, 6))\n","        # backward (hidden)\n","        backflow = delta_out @ self.out.W.T\n","        delta_h = d_sigmoid(self.hidden.A) * backflow\n","        print(\"[Backward] hidden delta:\", np.round(delta_h, 6))\n","        dW_h = self.hidden.X.T @ delta_h\n","        db_h = delta_h.sum(axis=0)\n","        self.hidden.W += self.lr * dW_h\n","        self.hidden.b += self.lr * db_h\n","        print(\"[Update] hidden W:\\n\", np.round(self.hidden.W, 6))\n","        print(\"[Update] hidden b:\", np.round(self.hidden.b, 6))\n","\n","if __name__ == \"__main__\":\n","    np.set_printoptions(suppress=True)\n","\n","    # Example sample (batch=1): 4 inputs → 2 targets\n","    X = np.array([[1.0, 0.0, 1.0, 0.0]])  # shape (1,4)\n","    T = np.array([[1.0, 0.0]])            # shape (1,2)\n","\n","    nn = NeuralNetwork432(lr=0.9)\n","    print(\"[Before] predict:\", np.round(nn.forward(X), 6))\n","    nn.train_one_step_verbose(X, T)\n","    print(\"[After ] predict:\", np.round(nn.forward(X), 6))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0w2db6K_-LMx","executionInfo":{"status":"ok","timestamp":1754745951660,"user_tz":-330,"elapsed":41,"user":{"displayName":"Aadhithya .U","userId":"10970561894782391279"}},"outputId":"7f0950a2-42c9-4e6d-f6de-2a27b8dd9a90"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[Before] predict: [[0.524598 0.523482]]\n","[Forward] hidden Z: [[0.043064 0.091206 0.133167]]\n","[Forward] hidden A: [[0.510764 0.522786 0.533243]]\n","[Forward] output Z: [[0.098472 0.093998]]\n","[Forward] output A: [[0.524598 0.523482]]\n","[Backward] output delta: [[ 0.118563 -0.130582]]\n","[Update] output W:\n"," [[ 0.150261 -0.022465]\n"," [ 0.12236  -0.026617]\n"," [ 0.084575  0.04349 ]]\n","[Update] output b: [ 0.106707 -0.117524]\n","[Backward] hidden delta: [[0.005185 0.004486 0.001082]]\n","[Update] hidden W:\n"," [[ 0.052225  0.017541  0.110679]\n"," [-0.045499 -0.167539 -0.055455]\n"," [ 0.000171  0.081741  0.024436]\n"," [ 0.054336  0.033211  0.034501]]\n","[Update] hidden b: [0.004666 0.004038 0.000974]\n","[After ] predict: [[0.572847 0.470073]]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","def sigmoid(x):\n","    return 1.0 / (1.0 + np.exp(-x))\n","\n","def d_sigmoid(a):\n","    return a * (1.0 - a)\n","\n","class DenseLayer:\n","    def __init__(self, n_in, n_out, lr=0.9, W=None, b=None, name=\"\"):\n","        self.n_in = n_in\n","        self.n_out = n_out\n","        self.lr = lr\n","        self.name = name\n","        self.W = np.array(W, dtype=float) if W is not None else np.random.randn(n_in, n_out) * 0.1\n","        self.b = np.array(b, dtype=float) if b is not None else np.zeros(n_out)\n","        self.X = None\n","        self.Z = None\n","        self.A = None\n","\n","    def forward(self, X):\n","        self.X = X\n","        self.Z = X @ self.W + self.b\n","        self.A = sigmoid(self.Z)\n","        return self.A\n","\n","    def backward_output(self, T):\n","        O = self.A\n","        delta = d_sigmoid(O) * (T - O)\n","        dW = self.X.T @ delta\n","        db = delta.sum(axis=0)\n","        self.W += self.lr * dW\n","        self.b += self.lr * db\n","        return delta\n","\n","    def backward_hidden(self, next_W, next_delta):\n","        O = self.A\n","        backflow = next_delta @ next_W.T\n","        delta = d_sigmoid(O) * backflow\n","        dW = self.X.T @ delta\n","        db = delta.sum(axis=0)\n","        self.W += self.lr * dW\n","        self.b += self.lr * db\n","        return delta\n","\n","class NeuralNetwork431:\n","    \"\"\"4 -> 3 -> 1\"\"\"\n","    def __init__(self, lr=0.9, init_params=None):\n","        self.lr = lr\n","        if init_params is not None:\n","            (W1, b1), (W2, b2) = init_params\n","        else:\n","            W1 = b1 = W2 = b2 = None\n","        self.hidden = DenseLayer(4, 3, lr=lr, W=W1, b=b1, name=\"hidden\")\n","        self.out    = DenseLayer(3, 1, lr=lr, W=W2, b=b2, name=\"output\")\n","\n","    def forward(self, X):\n","        H = self.hidden.forward(X)\n","        O = self.out.forward(H)\n","        return O\n","\n","    def backward_one_step(self, T):\n","        delta_out = self.out.backward_output(T)\n","        _ = self.hidden.backward_hidden(self.out.W, delta_out)\n","        return delta_out, _\n","\n","    def train_one_step_verbose(self, X, T):\n","        # forward\n","        H = self.hidden.forward(X)\n","        O = self.out.forward(H)\n","        print(\"[Forward] hidden Z:\", np.round(self.hidden.Z, 6))\n","        print(\"[Forward] hidden A:\", np.round(self.hidden.A, 6))\n","        print(\"[Forward] output Z:\", np.round(self.out.Z, 6))\n","        print(\"[Forward] output A:\", np.round(self.out.A, 6))\n","        # backward (output)\n","        O_last = self.out.A\n","        delta_out = d_sigmoid(O_last) * (T - O_last)\n","        print(\"[Backward] output delta:\", np.round(delta_out, 6))\n","        dW = self.out.X.T @ delta_out\n","        db = delta_out.sum(axis=0)\n","        self.out.W += self.lr * dW\n","        self.out.b += self.lr * db\n","        print(\"[Update] output W:\\n\", np.round(self.out.W, 6))\n","        print(\"[Update] output b:\", np.round(self.out.b, 6))\n","        # backward (hidden)\n","        backflow = delta_out @ self.out.W.T\n","        delta_h = d_sigmoid(self.hidden.A) * backflow\n","        print(\"[Backward] hidden delta:\", np.round(delta_h, 6))\n","        dW_h = self.hidden.X.T @ delta_h\n","        db_h = delta_h.sum(axis=0)\n","        self.hidden.W += self.lr * dW_h\n","        self.hidden.b += self.lr * db_h\n","        print(\"[Update] hidden W:\\n\", np.round(self.hidden.W, 6))\n","        print(\"[Update] hidden b:\", np.round(self.hidden.b, 6))\n","\n","if __name__ == \"__main__\":\n","    np.set_printoptions(suppress=True)\n","\n","    # Example sample (batch=1): 4 inputs → 1 target\n","    X = np.array([[0.0, 1.0, 1.0, 0.0]])  # shape (1,4)\n","    T = np.array([[1.0]])                 # shape (1,1)\n","\n","    nn = NeuralNetwork431(lr=0.9)\n","    print(\"[Before] predict:\", np.round(nn.forward(X), 6))\n","    nn.train_one_step_verbose(X, T)\n","    print(\"[After ] predict:\", np.round(nn.forward(X), 6))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q11g904TAoAv","executionInfo":{"status":"ok","timestamp":1754745966491,"user_tz":-330,"elapsed":88,"user":{"displayName":"Aadhithya .U","userId":"10970561894782391279"}},"outputId":"9e457df0-5280-4bfe-e137-35bf712a7ab6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[Before] predict: [[0.518249]]\n","[Forward] hidden Z: [[-0.045214 -0.372256  0.008378]]\n","[Forward] hidden A: [[0.488698 0.407996 0.502094]]\n","[Forward] output Z: [[0.073029]]\n","[Forward] output A: [[0.518249]]\n","[Backward] output delta: [[0.120277]]\n","[Update] output W:\n"," [[0.011212]\n"," [0.024957]\n"," [0.255985]]\n","[Update] output b: [0.10825]\n","[Backward] hidden delta: [[0.000337 0.000725 0.007697]]\n","[Update] hidden W:\n"," [[ 0.123219  0.074843 -0.024056]\n"," [-0.01255  -0.221387  0.001769]\n"," [-0.032058 -0.149564  0.020464]\n"," [ 0.080371  0.057306 -0.033827]]\n","[Update] hidden b: [0.000303 0.000653 0.006927]\n","[After ] predict: [[0.563108]]\n"]}]}]}